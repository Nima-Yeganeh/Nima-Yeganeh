{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('0.jpeg')\n",
    "# initilization of window\n",
    "cv2.namedWindow('IMAGE',0)\n",
    "\n",
    "cv2.imshow('IMAGE',img)\n",
    "cv2.imwrite('output.jpeg',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 24 146 162]\n",
      "  [ 21 146 166]\n",
      "  [ 16 147 174]\n",
      "  ...\n",
      "  [  7 146 172]\n",
      "  [ 16 149 169]\n",
      "  [ 23 155 172]]\n",
      "\n",
      " [[ 24 151 166]\n",
      "  [ 22 151 170]\n",
      "  [ 15 151 177]\n",
      "  ...\n",
      "  [  7 151 176]\n",
      "  [ 13 152 171]\n",
      "  [ 17 156 172]]\n",
      "\n",
      " [[ 22 159 175]\n",
      "  [ 19 158 177]\n",
      "  [ 14 157 184]\n",
      "  ...\n",
      "  [ 13 165 189]\n",
      "  [ 14 164 181]\n",
      "  [ 17 166 180]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  6 176 194]\n",
      "  [  2 174 192]\n",
      "  [  8 179 201]\n",
      "  ...\n",
      "  [  1 186 196]\n",
      "  [  0 183 188]\n",
      "  [  0 175 178]]\n",
      "\n",
      " [[  0 167 185]\n",
      "  [  0 167 185]\n",
      "  [  0 168 191]\n",
      "  ...\n",
      "  [  0 177 188]\n",
      "  [  0 180 188]\n",
      "  [  0 180 186]]\n",
      "\n",
      " [[  0 162 180]\n",
      "  [  0 163 181]\n",
      "  [  0 161 184]\n",
      "  ...\n",
      "  [  0 168 182]\n",
      "  [  0 173 183]\n",
      "  [  0 181 189]]]\n",
      "<class 'numpy.ndarray'>\n",
      "920\n",
      "752\n",
      "3\n",
      "(920, 752, 3)\n",
      "uint8\n",
      "[[24 21 16 ...  7 16 23]\n",
      " [24 22 15 ...  7 13 17]\n",
      " [22 19 14 ... 13 14 17]\n",
      " ...\n",
      " [ 6  2  8 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "[ 86 162 214]\n"
     ]
    }
   ],
   "source": [
    "#access and understand pixel data\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread('0.jpeg')\n",
    "\n",
    "print(img)\n",
    "print(type(img))\n",
    "print(len(img))\n",
    "print(len(img[0]))\n",
    "print(len(img[0][0]))\n",
    "print(img.shape)\n",
    "print(img.dtype)\n",
    "print(img[:,:,0])      #red channel\n",
    "print(img[10][15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1 1 1]\n",
      "[65535 65535 65535]\n",
      "[255   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Data types and structures\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "black=np.zeros([150,150,1],'uint8')\n",
    "cv2.imshow('black',black)\n",
    "print(black[0,0,:])\n",
    "\n",
    "ones=np.ones([150,150,3],'uint8')\n",
    "# ones*=(2**8-1)\n",
    "cv2.imshow('ones',ones)\n",
    "print(ones[0,0,:])\n",
    "\n",
    "white=np.ones([150,150,3],'uint16')\n",
    "white*=(2**16-1)\n",
    "cv2.imshow('white',white)\n",
    "print(white[0,0,:])\n",
    "\n",
    "#\n",
    "color=ones.copy()\n",
    "color[:,:]=(255,0,0) #blue\n",
    "cv2.imshow('blue',color)\n",
    "print(color[0,0,:])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 752, 3)\n"
     ]
    }
   ],
   "source": [
    "# image types and color channels\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('0.jpeg',1)\n",
    "cv2.imshow('image',img)\n",
    "cv2.moveWindow('image',0,0)\n",
    "\n",
    "print(img.shape)\n",
    "width,height,channel=img.shape\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel manipulation and filtering\n",
    "import cv2\n",
    "img=cv2.imread('0.jpeg',1)\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow('KESHAV',gray)\n",
    "\n",
    "r=img[:,:,0]\n",
    "g=img[:,:,1]\n",
    "b=img[:,:,2]\n",
    "\n",
    "rgba=cv2.merge((r,g,b,g))\n",
    "cv2.imshow('rgba',rgba)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gussian Blur,dilation and erosion\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('0.jpeg',1)\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "# blur\n",
    "blur=cv2.GaussianBlur(img,(5,55),0)\n",
    "cv2.imshow('Gaussian Blur',blur)\n",
    "\n",
    "kernel=np.ones((5,5),'uint8')\n",
    "dilate=cv2.dilate(img,kernel,iterations=1)\n",
    "erode=cv2.erode(img,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow('dilate',dilate)\n",
    "cv2.imshow('erode',erode)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and rotate image\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('0.jpeg',1)\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "# scale\n",
    "half=cv2.resize(img,(0,0),fx=0.5,fy=0.5,)\n",
    "cv2.imshow('half',half)\n",
    "\n",
    "stretch_=cv2.resize(img,(600,600),fx=0.5,fy=0.5)\n",
    "cv2.imshow('stretch_',stretch_)\n",
    "\n",
    "stretch_near_=cv2.resize(img,(600,600),fx=0.5,fy=0.5,interpolation = cv2.INTER_NEAREST)\n",
    "cv2.imshow('stretch_near_',stretch_near_)\n",
    "\n",
    "# rotate\n",
    "M=cv2.getRotationMatrix2D((0,0),-30,1)\n",
    "rotated=cv2.warpAffine(img,M,(img.shape[1],img.shape[0]))\n",
    "cv2.imshow('rotated',rotated)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video inputs\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('keshav',frame)\n",
    "    if cv2.waitKey(1)&0xff==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom interface\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "# circle\n",
    "color=(0,255,0)\n",
    "point=(200,200)\n",
    "radius=40\n",
    "border_width=6\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.circle(frame,point,radius,color,border_width)\n",
    "    cv2.imshow('keshav',frame)\n",
    "    if cv2.waitKey(1)&0xff==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressed:  526 347\n",
      "Pressed:  332 243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "# circle\n",
    "color=(0,255,0)\n",
    "point=(200,200)\n",
    "radius=40\n",
    "border_width=6\n",
    "def click(event,x,y,flags,param):\n",
    "    global point,pressed\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        print('Pressed: ',x,y)\n",
    "        point=(x,y)\n",
    "cv2.namedWindow('keshav')\n",
    "cv2.setMouseCallback('keshav',click)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.circle(frame,point,radius,color,border_width)\n",
    "    cv2.imshow('keshav',frame)\n",
    "    if cv2.waitKey(1)&0xff==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing App\n",
    "import numpy as np\n",
    "import cv2\n",
    "# cap=cv2.VideoCapture(0)\n",
    "keshav=np.ones([500,500,3],'uint8')*255\n",
    "radius=3\n",
    "color=(0,255,0)\n",
    "pressed=False\n",
    "def click(event,x,y,flags,param):\n",
    "    global keshav,pressed\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        pressed=True\n",
    "        cv2.circle(keshav,(x,y),radius,color,-1)\n",
    "    elif event==cv2.EVENT_MOUSEMOVE and pressed==True:\n",
    "        cv2.circle(keshav,(x,y),radius,color,-1)\n",
    "    elif event==cv2.EVENT_LBUTTONUP:\n",
    "        pressed=False\n",
    "cv2.namedWindow('keshav')\n",
    "cv2.setMouseCallback('keshav',click)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('keshav',keshav)\n",
    "    if cv2.waitKey(1)&0xff==ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1)&0xff==ord('b'):\n",
    "        color=(255,0,0)\n",
    "    elif cv2.waitKey(1)&0xff==ord('g'):\n",
    "        color=(0,255,0)\n",
    "    elif cv2.waitKey(1)&0xff==ord('r'):\n",
    "        color=(0,0,255)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 3\n",
    "# segmentation\n",
    "# simple threading\n",
    "import numpy as np\n",
    "import cv2\n",
    "bw=cv2.imread('0.jpeg',0)\n",
    "cv2.imshow('Original',bw)\n",
    "\n",
    "'method1'\n",
    "height,width=bw.shape[0:2]\n",
    "binary=np.zeros([height,width,3],'uint8')\n",
    "thresh=85\n",
    "for row in range(0,height):\n",
    "    for col in range(0,width):\n",
    "        if bw[row][col]>thresh:\n",
    "            binary[row][col]=255\n",
    "cv2.imshow('binary',binary)\n",
    "\n",
    "'method2'\n",
    "ret,thresh=cv2.threshold(bw,thresh,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive threading --->  https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-2-adaptive-thresholding\n",
    "import cv2\n",
    "img=cv2.imread('sudoku.png',0)\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "# simaple threading ---> problem ---> uneven binding\n",
    "ret,frame=cv2.threshold(img,85,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Binary',frame)\n",
    "\n",
    "# adaptive threading ---> remove uneven binding\n",
    "adap_thresh=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "cv2.imshow('adaptive thresh',adap_thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otsu threading ---> https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-3-otsu-thresholding/\n",
    "'We use the Traditional cv2.threshold function and use cv2.THRESH_OTSU as an extra flag.'\n",
    "import cv2\n",
    "img=cv2.imread('sudoku.png',0)\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "# simaple threading ---> problem ---> uneven binding\n",
    "ret,frame=cv2.threshold(img,85,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Binary',frame)\n",
    "\n",
    "# otsu\n",
    "ret,frame=cv2.threshold(img,85,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow('Otsu',frame)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skin detection ---> \n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread('faces.jpeg',1)\n",
    "hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('HSV',hsv)\n",
    "\n",
    "h=hsv[:,:,0]\n",
    "s=hsv[:,:,1]\n",
    "v=hsv[:,:,2]\n",
    "hsv_split=np.concatenate((h,s,v),axis=1)\n",
    "cv2.imshow('HSV_SPLIT',hsv_split)\n",
    "\n",
    "# detect\n",
    "ret,min_set=cv2.threshold(s,40,255,cv2.THRESH_BINARY)\n",
    "ret,max_set=cv2.threshold(h,15,255,cv2.THRESH_BINARY)\n",
    "final=cv2.bitwise_and(min_set,max_set)\n",
    "cv2.imshow('Final',final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object detection\n",
    "import cv2\n",
    "img=cv2.imread('detect_blob.png')\n",
    "cv2.imshow('Original colored',img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Gray',gray)\n",
    "\n",
    "\n",
    "thresh=cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "cv2.imshow('Thresh',thresh)\n",
    "\n",
    "_,contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "img2=img.copy()\n",
    "index=-1\n",
    "thickness=5\n",
    "color=(255,0,255)\n",
    "cv2.drawContours(img2,contours,index,color,thickness)\n",
    "cv2.imshow('Contours',img2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Area: 86.5,  perimeter: 45.55634891986847\n",
      "2 Area: 959.5,  perimeter: 251.8406196832657\n",
      "3 Area: 13091.5,  perimeter: 754.0416301488876\n",
      "4 Area: 10069.5,  perimeter: 401.41421353816986\n",
      "5 Area: 7780.0,  perimeter: 329.22034430503845\n",
      "6 Area: 4160.0,  perimeter: 258.0\n",
      "7 Area: 1672.0,  perimeter: 160.48528122901917\n",
      "8 Area: 14515.0,  perimeter: 1225.768675327301\n",
      "9 Area: 6569.0,  perimeter: 441.5979790687561\n",
      "10 Area: 7701.0,  perimeter: 484.8284270763397\n",
      "11 Area: 5581.0,  perimeter: 500.9604583978653\n",
      "12 Area: 5019.0,  perimeter: 357.2792183160782\n",
      "13 Area: 5019.0,  perimeter: 444.3675308227539\n",
      "14 Area: 8826.0,  perimeter: 449.76449966430664\n",
      "15 Area: 181.0,  perimeter: 54.62741661071777\n",
      "16 Area: 551.5,  perimeter: 93.41421353816986\n",
      "17 Area: 2708.5,  perimeter: 194.75230729579926\n",
      "18 Area: 1644.5,  perimeter: 152.1248904466629\n",
      "19 Area: 767.0,  perimeter: 105.74011433124542\n",
      "20 Area: 3505.5,  perimeter: 251.0710676908493\n",
      "21 Area: 8556.0,  perimeter: 345.70562493801117\n",
      "22 Area: 8909.0,  perimeter: 379.65685415267944\n",
      "23 Area: 924.0,  perimeter: 196.28427064418793\n",
      "24 Area: 1747.0,  perimeter: 253.82337403297424\n",
      "25 Area: 747.0,  perimeter: 102.9116872549057\n",
      "26 Area: 1638.0,  perimeter: 152.36753034591675\n",
      "27 Area: 1.0,  perimeter: 4114.82842707634\n"
     ]
    }
   ],
   "source": [
    "# Area, Perimeter, Center, Curvature\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('detect_blob.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "thresh=cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "_,contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img2=img.copy()\n",
    "color=(123,255,61)\n",
    "index=-1\n",
    "tk=2\n",
    "frame=np.zeros([img.shape[0],img.shape[1],3],'uint8')\n",
    "i=1\n",
    "for c in contours:\n",
    "    cv2.drawContours(frame,[c],index,color,tk)\n",
    "    area=cv2.contourArea(c)\n",
    "    arclength=cv2.arcLength(c,True)\n",
    "    print('{} Area: {},  perimeter: {}'.format(i,area,arclength))\n",
    "    i+=1\n",
    "    m=cv2.moments(c)\n",
    "    cx=int(m['m10']/m['m00'])\n",
    "    cy=int(m['m01']/m['m00'])\n",
    "    cv2.circle(frame,(cx,cy),1,(0,0,255),-1)\n",
    "    cv2.imshow('Original',frame)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "img=cv2.imread('tomatoes.jpg')\n",
    "HSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "ret,thresh=cv2.threshold(HSV[:,:,0],25,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "edges=cv2.Canny(img,100,70)\n",
    "cv2.imshow('Edges',edges)\n",
    "\n",
    "final=cv2.bitwise_or(thresh,edges)\n",
    "cv2.imshow('Final',final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH-4 --> Face Detection\n",
    "# Template Matching\n",
    "import numpy as np\n",
    "import cv2\n",
    "template=cv2.imread('template.jpg')\n",
    "frame=cv2.imread('players.jpg')\n",
    "cv2.imshow('Template',template)\n",
    "cv2.imshow('Frame',frame)\n",
    "\n",
    "result=cv2.matchTemplate(frame,template,cv2.TM_CCOEFF_NORMED)\n",
    "cv2.imshow('result1',result)\n",
    "min_val,max_val,min_loc,max_loc=cv2.minMaxLoc(result)\n",
    "cv2.circle(result,max_loc,15,255,-1)\n",
    "cv2.imshow('result2',result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 243)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 191)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.43392035365104675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4392918348312378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('faces.jpeg')\n",
    "\n",
    "rimg=cv2.resize(img,(img.shape[0]//3,img.shape[1]//5),interpolation=cv2.INTER_AREA)\n",
    "gray=cv2.cvtColor(rimg,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "path='haarcascade_frontalface_default.xml'\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier(path)\n",
    "faces=face_cascade.detectMultiScale(gray,scaleFactor=1.25,minSize=(40,40))\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(rimg,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "cv2.imshow('Img',rimg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('faces.jpeg')\n",
    "\n",
    "rimg=cv2.resize(img,(img.shape[0]//3,img.shape[1]//5),interpolation=cv2.INTER_AREA)\n",
    "gray=cv2.cvtColor(rimg,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "path='haarcascade_eye.xml'\n",
    "\n",
    "eye_cascade=cv2.CascadeClassifier(path)\n",
    "eyes=eye_cascade.detectMultiScale(gray,scaleFactor=1.04,minNeighbors=20,minSize=(10,10))\n",
    "\n",
    "for (x,y,w,h) in eyes:\n",
    "    cx=(x+x+w)//2\n",
    "    cy=(y+y+h)//2\n",
    "    cv2.circle(rimg,(cx,cy),w//2,(255,0,0),2)\n",
    "cv2.imshow('Img',rimg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
